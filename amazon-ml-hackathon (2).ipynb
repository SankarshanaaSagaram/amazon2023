{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-23T05:41:20.594145Z","iopub.execute_input":"2023-04-23T05:41:20.594553Z","iopub.status.idle":"2023-04-23T05:41:20.607111Z","shell.execute_reply.started":"2023-04-23T05:41:20.594518Z","shell.execute_reply":"2023-04-23T05:41:20.606109Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-ml-challenge-2025/dataset/sample_submission.csv\n/kaggle/input/amazon-ml-challenge-2025/dataset/train.csv\n/kaggle/input/amazon-ml-challenge-2025/dataset/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/amazon-ml-challenge-2025/dataset/train.csv')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:20.609545Z","iopub.execute_input":"2023-04-23T05:41:20.610178Z","iopub.status.idle":"2023-04-23T05:41:45.968668Z","shell.execute_reply.started":"2023-04-23T05:41:20.610140Z","shell.execute_reply":"2023-04-23T05:41:45.967275Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID                                              TITLE  \\\n0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n4      283658  The United Empire Loyalists: A Chronicle of th...   \n\n                                       BULLET_POINTS  \\\n0  [LUXURIOUS & APPEALING: Beautiful custom-made ...   \n1  [Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...   \n2  [Loud Dual Tone Trumpet Horn, Compatible With ...   \n3  [Made By 95%cotton and 5% Lycra which gives yo...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \\\n0                                                NaN             1650   \n1                                                NaN             2755   \n2  Specifications: Color: Red, Material: Aluminiu...             7537   \n3  AISHAH Women's Lycra Cotton Ankel Leggings. Br...             2996   \n4                                                NaN             6112   \n\n   PRODUCT_LENGTH  \n0     2125.980000  \n1      393.700000  \n2      748.031495  \n3      787.401574  \n4      598.424000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n      <td>[LUXURIOUS &amp; APPEALING: Beautiful custom-made ...</td>\n      <td>NaN</td>\n      <td>1650</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n      <td>[Harry Potter Hedwig Pyjamas (6-16 Yrs),100% c...</td>\n      <td>NaN</td>\n      <td>2755</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n      <td>[Loud Dual Tone Trumpet Horn, Compatible With ...</td>\n      <td>Specifications: Color: Red, Material: Aluminiu...</td>\n      <td>7537</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n      <td>[Made By 95%cotton and 5% Lycra which gives yo...</td>\n      <td>AISHAH Women's Lycra Cotton Ankel Leggings. Br...</td>\n      <td>2996</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>The United Empire Loyalists: A Chronicle of th...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6112</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/amazon-ml-challenge-2025/dataset/test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:45.970954Z","iopub.execute_input":"2023-04-23T05:41:45.971743Z","iopub.status.idle":"2023-04-23T05:41:54.257238Z","shell.execute_reply.started":"2023-04-23T05:41:45.971702Z","shell.execute_reply":"2023-04-23T05:41:54.256080Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID                                              TITLE  \\\n0      604373  Manuel d'Héliogravure Et de Photogravure En Re...   \n1     1729783  DCGARING Microfiber Throw Blanket Warm Fuzzy P...   \n2     1871949  I-Match Auto Parts Front License Plate Bracket...   \n3     1107571  PinMart Gold Plated Excellence in Service 1 Ye...   \n4      624253  Visual Mathematics, Illustrated by the TI-92 a...   \n\n                                       BULLET_POINTS  \\\n0                                                NaN   \n1  [QUALITY GUARANTEED: Luxury cozy plush polyest...   \n2  [Front License Plate Bracket Made Of Plastic,D...   \n3  [Available as a single item or bulk packed. Se...   \n4                                                NaN   \n\n                                         DESCRIPTION  PRODUCT_TYPE_ID  \n0                                                NaN             6142  \n1  <b>DCGARING Throw Blanket</b><br><br> <b>Size ...             1622  \n2  Replacement for The Following Vehicles:2020 LE...             7540  \n3  Our Excellence in Service Lapel Pins feature a...            12442  \n4                                                NaN             6318  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>BULLET_POINTS</th>\n      <th>DESCRIPTION</th>\n      <th>PRODUCT_TYPE_ID</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>604373</td>\n      <td>Manuel d'Héliogravure Et de Photogravure En Re...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6142</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1729783</td>\n      <td>DCGARING Microfiber Throw Blanket Warm Fuzzy P...</td>\n      <td>[QUALITY GUARANTEED: Luxury cozy plush polyest...</td>\n      <td>&lt;b&gt;DCGARING Throw Blanket&lt;/b&gt;&lt;br&gt;&lt;br&gt; &lt;b&gt;Size ...</td>\n      <td>1622</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1871949</td>\n      <td>I-Match Auto Parts Front License Plate Bracket...</td>\n      <td>[Front License Plate Bracket Made Of Plastic,D...</td>\n      <td>Replacement for The Following Vehicles:2020 LE...</td>\n      <td>7540</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1107571</td>\n      <td>PinMart Gold Plated Excellence in Service 1 Ye...</td>\n      <td>[Available as a single item or bulk packed. Se...</td>\n      <td>Our Excellence in Service Lapel Pins feature a...</td>\n      <td>12442</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>624253</td>\n      <td>Visual Mathematics, Illustrated by the TI-92 a...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>6318</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:54.258749Z","iopub.execute_input":"2023-04-23T05:41:54.259490Z","iopub.status.idle":"2023-04-23T05:41:54.271531Z","shell.execute_reply.started":"2023-04-23T05:41:54.259441Z","shell.execute_reply":"2023-04-23T05:41:54.270239Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 2249698 entries, 0 to 2249697\nData columns (total 6 columns):\n #   Column           Dtype  \n---  ------           -----  \n 0   PRODUCT_ID       int64  \n 1   TITLE            object \n 2   BULLET_POINTS    object \n 3   DESCRIPTION      object \n 4   PRODUCT_TYPE_ID  int64  \n 5   PRODUCT_LENGTH   float64\ndtypes: float64(1), int64(2), object(3)\nmemory usage: 103.0+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"test.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:54.275162Z","iopub.execute_input":"2023-04-23T05:41:54.275804Z","iopub.status.idle":"2023-04-23T05:41:54.490674Z","shell.execute_reply.started":"2023-04-23T05:41:54.275753Z","shell.execute_reply":"2023-04-23T05:41:54.489490Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 734736 entries, 0 to 734735\nData columns (total 5 columns):\n #   Column           Non-Null Count   Dtype \n---  ------           --------------   ----- \n 0   PRODUCT_ID       734736 non-null  int64 \n 1   TITLE            734731 non-null  object\n 2   BULLET_POINTS    458814 non-null  object\n 3   DESCRIPTION      354735 non-null  object\n 4   PRODUCT_TYPE_ID  734736 non-null  int64 \ndtypes: int64(2), object(3)\nmemory usage: 28.0+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.impute import KNNImputer","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:54.492127Z","iopub.execute_input":"2023-04-23T05:41:54.492558Z","iopub.status.idle":"2023-04-23T05:41:54.498547Z","shell.execute_reply.started":"2023-04-23T05:41:54.492519Z","shell.execute_reply":"2023-04-23T05:41:54.497401Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"n=train.isnull().sum()\nn","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:54.500143Z","iopub.execute_input":"2023-04-23T05:41:54.500589Z","iopub.status.idle":"2023-04-23T05:41:55.130240Z","shell.execute_reply.started":"2023-04-23T05:41:54.500549Z","shell.execute_reply":"2023-04-23T05:41:55.129039Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"PRODUCT_ID               0\nTITLE                   12\nBULLET_POINTS       837364\nDESCRIPTION        1157381\nPRODUCT_TYPE_ID          0\nPRODUCT_LENGTH           0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"1157381/2249698","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:55.131580Z","iopub.execute_input":"2023-04-23T05:41:55.132311Z","iopub.status.idle":"2023-04-23T05:41:55.139400Z","shell.execute_reply.started":"2023-04-23T05:41:55.132264Z","shell.execute_reply":"2023-04-23T05:41:55.138091Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0.5144606076015537"},"metadata":{}}]},{"cell_type":"code","source":"train2 = train.drop(['DESCRIPTION', 'BULLET_POINTS'], axis=1)\ntrain2.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:41:55.141312Z","iopub.execute_input":"2023-04-23T05:41:55.141681Z","iopub.status.idle":"2023-04-23T05:41:55.228882Z","shell.execute_reply.started":"2023-04-23T05:41:55.141624Z","shell.execute_reply":"2023-04-23T05:41:55.227687Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID                                              TITLE  \\\n0     1925202  ArtzFolio Tulip Flowers Blackout Curtain for D...   \n1     2673191  Marks & Spencer Girls' Pyjama Sets T86_2561C_N...   \n2     2765088  PRIKNIK Horn Red Electric Air Horn Compressor ...   \n3     1594019  ALISHAH Women's Cotton Ankle Length Leggings C...   \n4      283658  The United Empire Loyalists: A Chronicle of th...   \n\n   PRODUCT_TYPE_ID  PRODUCT_LENGTH  \n0             1650     2125.980000  \n1             2755      393.700000  \n2             7537      748.031495  \n3             2996      787.401574  \n4             6112      598.424000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>TITLE</th>\n      <th>PRODUCT_TYPE_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>ArtzFolio Tulip Flowers Blackout Curtain for D...</td>\n      <td>1650</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>Marks &amp; Spencer Girls' Pyjama Sets T86_2561C_N...</td>\n      <td>2755</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>PRIKNIK Horn Red Electric Air Horn Compressor ...</td>\n      <td>7537</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>ALISHAH Women's Cotton Ankle Length Leggings C...</td>\n      <td>2996</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>The United Empire Loyalists: A Chronicle of th...</td>\n      <td>6112</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"cluster_data = train2.drop(['TITLE','PRODUCT_TYPE_ID'], axis = 1)\ncluster_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:57:48.269622Z","iopub.execute_input":"2023-04-23T05:57:48.270526Z","iopub.status.idle":"2023-04-23T05:57:48.299302Z","shell.execute_reply.started":"2023-04-23T05:57:48.270481Z","shell.execute_reply":"2023-04-23T05:57:48.297938Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"   PRODUCT_ID  PRODUCT_LENGTH\n0     1925202     2125.980000\n1     2673191      393.700000\n2     2765088      748.031495\n3     1594019      787.401574\n4      283658      598.424000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PRODUCT_ID</th>\n      <th>PRODUCT_LENGTH</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1925202</td>\n      <td>2125.980000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2673191</td>\n      <td>393.700000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2765088</td>\n      <td>748.031495</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1594019</td>\n      <td>787.401574</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>283658</td>\n      <td>598.424000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"transformer implementation****","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn","metadata":{"execution":{"iopub.status.busy":"2023-04-23T05:57:39.588822Z","iopub.execute_input":"2023-04-23T05:57:39.589750Z","iopub.status.idle":"2023-04-23T05:57:42.245729Z","shell.execute_reply.started":"2023-04-23T05:57:39.589694Z","shell.execute_reply":"2023-04-23T05:57:42.244374Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"class SelfAttention(nn.Module):\n    def _init_(self, embed_size, heads):\n        super(SelfAttention,self)._init_()\n        self.embed_size = embed_size\n        self.head = heads\n        self.head_dim = embed_size // heads\n        \n        assert (self.head_dim * heads == embed_size) , \"Embed size needs to be divisible by heads\"\n        \n        self.values = nn.Linear(self.head_dim, self.head_dim, bias = False)\n        self.keys = nn.Linear(self.head_dim, self.head_dim, bias = False)\n        self.queries = nn.Linear(self.head_dim, self.head_dim, bias = False)\n        self.fc_out = nn.Linear(head*self.head_dim, embed_size)\n    \n    def forward(self, values, keys, query, mask):\n        N = query.shape[0]\n        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n        \n        # splitting embeddings into self.heads pieces\n        values = values.reshape(N, value_len, self.heads, self.head_dim)\n        keys = keys.reshape(N, key_len, self.heads, self.heads_dim)\n        queries = query.reshape(N, query_len, self.heads, self.head_dim)\n        \n        values = self.values(values)\n        keys = self.keys(keys)\n        queries = self.queries(queries)\n        \n        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries,keys])\n        #queries shape: (N, query_len, heads, heads_dim)\n        #keys shape: (N, key_len, heads, heads_dim)\n        #energy shape: (N, heads, query_len, key_len)\n        \n        if mask is not None:\n            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n            \n        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim = 3)\n        \n        out = torch.einsum(\"nhql,nlhd->nqhd\",[attention,values]).reshape()\n        #attention shape: (N, heads, query_len, key_len)\n        #values shape: (N, value_len, heads, heads_dim)\n        #after einsum: (N, query_len, heads, head_dim) then flatten last 2 dimensions\n        \n        out = self.fc_out(out)\n        return out\n        \n        ","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:52:36.693959Z","iopub.execute_input":"2023-04-23T06:52:36.694379Z","iopub.status.idle":"2023-04-23T06:52:36.708491Z","shell.execute_reply.started":"2023-04-23T06:52:36.694344Z","shell.execute_reply":"2023-04-23T06:52:36.707100Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"class TransformerBlock(nn.Module):\n    def _init_(self, embed_size, heads, dropout, forward_expansion):\n        super(TransformerBlock, self)._init_()\n        self.attention = SelfAttention(embedsize, heads)\n        self.norm1 = nn.LayerNorm(embed_size)\n        self.norm2 = nn.LayerNorm(embed_size)\n        \n        self.feed_forward = nn.Sequential(\n        nn.Linear(embed_size, forward_expansion*embed_size),\n        nn.ReLU(),\n        nn.Linear(forward_expansion*embed_size, embed_size)\n        )\n        self.droput = nn.Dropout(dropout)\n    \n    def forward(self, value, key, query, mask):\n        attention = self.attention(value, key, query, mask)\n        \n        x = self.dropout(self.norm1(attention + query))\n        forward = self.feed_forward(x)\n        out = self.dropout(self.norm2(forward + x))\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:52:40.062868Z","iopub.execute_input":"2023-04-23T06:52:40.064383Z","iopub.status.idle":"2023-04-23T06:52:40.074030Z","shell.execute_reply.started":"2023-04-23T06:52:40.064324Z","shell.execute_reply":"2023-04-23T06:52:40.072299Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(\n        self,\n        src_vocab_size,\n        embed_size,\n        num_layers,\n        heads,\n        device,\n        forward_expansion,\n        dropout,\n        max_length,\n    ):\n\n        super(Encoder, self).__init__()\n        self.embed_size = embed_size\n        self.device = device\n        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n        self.position_embedding = nn.Embedding(max_length, embed_size)\n\n        self.layers = nn.ModuleList(\n            [\n                TransformerBlock(\n                    embed_size,\n                    heads,\n                    dropout=dropout,\n                    forward_expansion=forward_expansion,\n                )\n                for _ in range(num_layers)\n            ]\n        )\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask):\n        N, seq_length = x.shape\n        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n        out = self.dropout(\n            (self.word_embedding(x) + self.position_embedding(positions))\n        )\n\n        # In the Encoder the query, key, value are all the same, it's in the\n        # decoder this will change. This might look a bit odd in this case.\n        for layer in self.layers:\n            out = layer(out, out, out, mask)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:52:42.793175Z","iopub.execute_input":"2023-04-23T06:52:42.793670Z","iopub.status.idle":"2023-04-23T06:52:42.806525Z","shell.execute_reply.started":"2023-04-23T06:52:42.793630Z","shell.execute_reply":"2023-04-23T06:52:42.805058Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class DecoderBlock(nn.Module):\n    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n        super(DecoderBlock, self).__init__()\n        self.norm = nn.LayerNorm(embed_size)\n        self.attention = SelfAttention(embed_size, heads=heads)\n        self.transformer_block = TransformerBlock(\n            embed_size, heads, dropout, forward_expansion\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, value, key, src_mask, trg_mask):\n        attention = self.attention(x, x, x, trg_mask)\n        query = self.dropout(self.norm(attention + x))\n        out = self.transformer_block(value, key, query, src_mask)\n        return out\n","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:52:50.292677Z","iopub.execute_input":"2023-04-23T06:52:50.294125Z","iopub.status.idle":"2023-04-23T06:52:50.302789Z","shell.execute_reply.started":"2023-04-23T06:52:50.294058Z","shell.execute_reply":"2023-04-23T06:52:50.301260Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(\n        self,\n        trg_vocab_size,\n        embed_size,\n        num_layers,\n        heads,\n        forward_expansion,\n        dropout,\n        device,\n        max_length,\n    ):\n        super(Decoder, self).__init__()\n        self.device = device\n        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n        self.position_embedding = nn.Embedding(max_length, embed_size)\n\n        self.layers = nn.ModuleList(\n            [\n                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n                for _ in range(num_layers)\n            ]\n        )\n        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, enc_out, src_mask, trg_mask):\n        N, seq_length = x.shape\n        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n\n        for layer in self.layers:\n            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n\n        out = self.fc_out(x)\n\n        return out","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:52:54.503347Z","iopub.execute_input":"2023-04-23T06:52:54.503921Z","iopub.status.idle":"2023-04-23T06:52:54.515654Z","shell.execute_reply.started":"2023-04-23T06:52:54.503876Z","shell.execute_reply":"2023-04-23T06:52:54.514167Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"class Transformer(nn.Module):\n    def _init_(\n        self,\n        src_vocab_size,\n        trg_vocab_size,\n        src_pad_idx,\n        trg_pad_idx,\n        embed_size=512,\n        num_layers=6,\n        forward_expansion=4,\n        heads=8,\n        dropout=0,\n        device=\"cuda\",\n        max_length=100,\n    ):\n\n        super(Transformer, self).__init__()\n\n        self.encoder = Encoder(\n            src_vocab_size,\n            embed_size,\n            num_layers,\n            heads,\n            device,\n            forward_expansion,\n            dropout,\n            max_length,\n        )\n\n        self.decoder = Decoder(\n            trg_vocab_size,\n            embed_size,\n            num_layers,\n            heads,\n            forward_expansion,\n            dropout,\n            device,\n            max_length,\n        )\n\n        self.src_pad_idx = src_pad_idx\n        self.trg_pad_idx = trg_pad_idx\n        self.device = device\n\n    def make_src_mask(self, src):\n        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n        # (N, 1, 1, src_len)\n        return src_mask.to(self.device)\n\n    def make_trg_mask(self, trg):\n        N, trg_len = trg.shape\n        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n            N, 1, trg_len, trg_len\n        )\n\n        return trg_mask.to(self.device)\n    def forward(self, src, trg):\n        src_mask = self.make_src_mask(src)\n        trg_mask = self.make_trg_mask(trg)\n        enc_src = self.encoder(src, src_mask)\n        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n        return out\n\n\nif __name__ == \"__main__\":\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n\n    x = torch.tensor([[1, 5, 6, 4, 3, 9, 5, 2, 0], [1, 8, 7, 3, 4, 5, 6, 7, 2]]).to(\n        device\n    )\n    trg = torch.tensor([[1, 7, 4, 3, 5, 9, 2, 0], [1, 5, 6, 2, 4, 7, 6, 2]]).to(device)\n\n    src_pad_idx = 0\n    trg_pad_idx = 0\n    src_vocab_size = 10\n    trg_vocab_size = 10\n    model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(\n        device\n    )\n    out = model(x, trg[:, :-1])\n    print(out.shape)","metadata":{"execution":{"iopub.status.busy":"2023-04-23T06:53:33.894457Z","iopub.execute_input":"2023-04-23T06:53:33.895590Z","iopub.status.idle":"2023-04-23T06:53:33.928065Z","shell.execute_reply.started":"2023-04-23T06:53:33.895543Z","shell.execute_reply":"2023-04-23T06:53:33.926345Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/361734394.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0msrc_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtrg_vocab_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     model = Transformer(src_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, device=device).to(\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     )\n","\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'device'"],"ename":"TypeError","evalue":"__init__() got an unexpected keyword argument 'device'","output_type":"error"}]}]}